################################################
#
# 统一 配置
#
################################################
# 滑动窗口(单位:秒)
spark.batch.duration=5
# 启动入口
spark.main.class=org.demo.EsSinkDemo
# 传入参数
spark.main.params=
# App 名字
spark.app.name=EsSinkDemo-online
# 部署模式
spark.master=yarn
spark.deploy.mode=cluster
# driver 节点内存分配
spark.driver.memory=512M
# 单个 executor 分配核心数
spark.executor.cores=3
# 单个 executor 申请 JVM Heap 大小
spark.executor.memory=5G
# 启用 External shuffle Service服务
spark.shuffle.service.enabled=true
# Shuffle Service服务端口，必须和yarn-site中的一致
spark.shuffle.service.port=7337
# 开启动态资源分配
spark.dynamicAllocation.enabled=true
# 每个Application最小分配的executor数
spark.dynamicAllocation.minExecutors=1
# 每个Application最大并发分配的executor数
spark.dynamicAllocation.maxExecutors=30
spark.dynamicAllocation.schedulerBacklogTimeout=1s
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=5s
################################################
#
# Kafka Source 配置
#
# 格式：spark.source.kafka.consume.{标准Kafka配置}
# 程序会自动截取前缀 spark.source.kafka.consume. 后注入到kafkaParams
#
################################################
#broker 地址
spark.source.kafka.consume.bootstrap.servers=hadoop102:9092,hadoop103:9092,hadoop104:9092,hadoop105:9092,hadoop106:9092,hadoop107:9092,hadoop108:9092
# 消费组
spark.source.kafka.consume.group.id=gn_test_v1
# 消费Topic 2
spark.source.kafka.consume.topics=druid_topic_kfk_applog_v2
#首次消费 读取位置 largest, smallest
spark.source.kafka.consume.auto.offset.reset=largest
spark.source.kafka.consume.socket.timeout.ms=120000
spark.source.kafka.consume.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
spark.source.kafka.consume.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
################################################
#
# Es Sink
################################################
spark.sink.es.es.nodes=hadoop97,hadoop98,hadoop99,hadoop100,hadoop101
spark.sink.es.es.port=9200
spark.sink.es.es.batch.size.entries=10000
spark.sink.es.es.index.auto.create=true
spark.sink.es.es.index=gn_test_v1
spark.sink.es.es.type=ymd
spark.sink.es.es.nodes.wan.only=true