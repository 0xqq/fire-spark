################################################
#
# 基础 配置
#
################################################
# 窗口批次时间（单位秒）
spark.batch.duration=10
# 启动入口
spark.main.class=org.demo.ReadKafkaDemoA
# 名称
spark.app.name=ReadKafkaDemoA-online
# 传入参数 可以为空
spark.main.params
# 部署模式
spark.master=yarn-cluster
# 启用 External shuffle Service服务
spark.shuffle.service.enabled=true
# Shuffle Service服务端口，必须和yarn-site中的一致
spark.shuffle.service.port=7337
# 开启动态资源分配
spark.dynamicAllocation.enabled=true
# 每个Application最小分配的executor数
spark.dynamicAllocation.minExecutors=1
# 每个Application最大并发分配的executor数
spark.dynamicAllocation.maxExecutors=30
spark.dynamicAllocation.schedulerBacklogTimeout=1s
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=5s
################################################
#
# Kafka Source 配置
#
################################################
# broker 地址
spark.source.kafka.metadata.broker.list=hadoop102:9092,hadoop103:9092,hadoop104:9092,hadoop105:9092,hadoop106:9092,hadoop107:9092,hadoop108:9092
# 消费组
spark.source.kafka.consume.group.id=consume_group_online_v1
# 消费后repartition数,0为不做repartition
spark.source.kafka.consume.repartition=0
# 消费Topic
spark.source.kafka.consume.topics=logbase
# 首次消费读取位置 largest | smallest
spark.source.kafka.auto.offset.reset=largest
# spark.source.kafka. 开头的配置，均会加载到 consume 配置中
spark.source.kafka.consume.socket.timeout.ms=120000
################################################
#
# 拥堵监控邮件配置
#
################################################
# 拥堵多少批次发送告警邮件
spark.monitor.congestion.batch=5
# 拥堵多少批次自杀
spark.monitor.suicide.batch=15
# 钉钉群告警@人手机号
spark.monitor.congestion.ding.to=18611111111
################################################
#
# ES 配置
#
################################################
spark.activity.sink.es.nodes=hadoop91,hadoop92,hadoop93,hadoop94,hadoop95,hadoop96,hadoop97,hadoop98,hadoop99,hadoop100,hadoop101
spark.activity.sink.es.port=9200
spark.activity.sink.es.batch.size.entries=10000
spark.activity.sink.es.index.auto.create=true
spark.activity.sink.es.index=activity-v1
spark.activity.sink.es.type=ymd

